{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16861,"status":"ok","timestamp":1655114668249,"user":{"displayName":"Dr MAG","userId":"10163411640105691678"},"user_tz":-60},"id":"vDtQiOesUF2y","outputId":"7be0e838-f0e7-45c9-afa0-e340c62e94f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: category_encoders in /usr/local/lib/python3.7/dist-packages (2.5.0)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.3.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->category_encoders) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n"]}],"source":["\n","# first neural network with keras tutorial\n","from numpy import loadtxt\n","import numpy as np\n","import pandas as pd\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","\n","# Installing required libraries\n","!pip install tensorflow\n","!pip install keras\n","!pip install category_encoders   # For Hash Encoding\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMM4WVvYUfTW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655114830578,"user_tz":-60,"elapsed":47831,"user":{"displayName":"Dr MAG","userId":"10163411640105691678"}},"outputId":"ea8c6ba1-3cb4-4661-c7b7-efbb8c765239"},"outputs":[{"output_type":"stream","name":"stdout","text":["columns are \n","df.columns =  Index(['Unnamed: 0', 'Domain', 'category'], dtype='object')\n","df [feature] =  0               andyburd.com\n","1               musicals.com\n","2                cultura.com\n","3                   ifly.com\n","4                 mirror.com\n","                 ...        \n","8708034      pillowsocks.com\n","8708035             gmhr.com\n","8708036         cerealty.com\n","8708037    stoneandcloth.com\n","8708038         ladyslim.com\n","Name: Domain, Length: 8708039, dtype: object\n","df after regex is  =          Unnamed: 0         Domain  category\n","0                 0       andyburd        10\n","1                 1       musicals        10\n","2                 2        cultura        10\n","3                 3           ifly        10\n","4                 4         mirror        10\n","...             ...            ...       ...\n","8708034     8708034    pillowsocks         3\n","8708035     8708035           gmhr         3\n","8708036     8708036       cerealty         3\n","8708037     8708037  stoneandcloth         3\n","8708038     8708038       ladyslim         3\n","\n","[8708039 rows x 3 columns]\n","df [feature] after string conversion=  0               andyburd\n","1               musicals\n","2                cultura\n","3                   ifly\n","4                 mirror\n","               ...      \n","8708034      pillowsocks\n","8708035             gmhr\n","8708036         cerealty\n","8708037    stoneandcloth\n","8708038         ladyslim\n","Name: Domain, Length: 8708039, dtype: object\n","df [target] after string conversion=  0          10\n","1          10\n","2          10\n","3          10\n","4          10\n","           ..\n","8708034     3\n","8708035     3\n","8708036     3\n","8708037     3\n","8708038     3\n","Name: category, Length: 8708039, dtype: int64\n"]}],"source":["# load the dataset\n","mayPath = '/content/drive/MyDrive/MY Startups/Misc/Domain Name valuation/Data/Cleaned Data/'\n","#fileName = '/content/drive/MyDrive/MY Startups/Misc/Domain Name valuation/Data/SmallExperimentData/MediumData.csv'\n","fileName = mayPath + 'DomainMergedFile.csv'\n","\n","df = pd.read_csv(fileName)\n","#Print some data\n","df.head()\n","\n","feature_col =  'Domain'\n","target_col  = 'category'\n","#print (df)\n","print('columns are ')\n","print('df.columns = ', df.columns )\n","print('df [feature] = ', df[feature_col])\n","\n","# Now replace strings '.com' as they are common everywhere\n","df[feature_col] = df[feature_col].replace({'.com': ''}, regex=True)\n","print ('df after regex is  =' ,df)\n","\n","#Check its type\n","#df[feature_col] = df[feature_col].astype('category')\n","# Lets check heads\n","print('df [feature] after string conversion= ', df[feature_col])\n","print('df [target] after string conversion= ', df[target_col])\n","\n"]},{"cell_type":"code","source":["############################################################################\n","# Many Encoding algorithms have been implemented\n","############################################################################\n","\n","\n","import category_encoders as ce\n","\n","\n","################################\n","# Hash Encoding\n","################################\n","# Hashing is giving 80% Accuracy on single file\n","# For merge file ....\n","\n","#Create object for hash encoder\n","encoder=ce.HashingEncoder(cols=feature_col,n_components=100)\n","\n","#creating instance of hash encoder\n","encoded_data = encoder.fit_transform(df)\n","\n","\n","\n","################################\n","# Binary Encoding\n","################################\n","# Hashing is giving 35% Accuracy\n","\n","'''\n","#Create object for hash encoder\n","encoder=ce.BinaryEncoder(cols=feature_col,return_df=True)\n","\n","#creating instance of binary\n","encoded_data = encoder.fit_transform(df)\n","'''\n","\n","'''\n","################################\n","# Base N Encoding\n","################################\n","# Extremely bas error, not recommended 7%\n","\n","#Create object for hash encoder\n","encoder= ce.BaseNEncoder(cols=feature_col,return_df=True,base=10)   # Base 5 is just an example, we need to see from Various experiments its value\n","\n","#creating instance of one-hot-encoder\n","encoded_data = encoder.fit_transform(df)\n","\n","'''\n","\n","\n","#######################################################\n","# Common steps for all of them\n","try:\n"," encoded_data.drop(['Unnamed: 0'], axis = 1, inplace=True) # Delete the index column, which is coming by error (we might need to DOUBLE CHECK THIS)\n","except: \n","  print('no errored col found, so ok to continue ')\n","\n","print('encoded_data  = ', encoded_data.columns)\n","\n","\n","x = encoded_data.drop([target_col], axis = 1)\n","y = encoded_data[target_col]\n","\n","print('x is  = ', x)\n","print('y is   = ', y)\n","\n","\n","# Some variables, which will be used while training the model\n","TargetVariable=[target_col] \n","Predictors= encoded_data.drop([target_col], axis = 1).columns\n","print('Input Feature col are =', Predictors)"],"metadata":{"id":"lcqeiT1As6yY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1655111382426,"user":{"displayName":"Dr MAG","userId":"10163411640105691678"},"user_tz":-60},"id":"47Nd8wPad2XM","outputId":"537f61b1-d191-4e8a-a32c-e4e3b92d453c"},"outputs":[{"output_type":"stream","name":"stdout","text":["total colums are =  7\n","X =          Domain_0  Domain_1  Domain_2  Domain_3  Domain_4  Domain_5\n","0              0         0         0         0         0         1\n","1              0         0         0         0         0         2\n","2              0         0         0         0         0         3\n","3              0         0         0         0         0         4\n","4              0         0         0         0         0         5\n","...          ...       ...       ...       ...       ...       ...\n","479514         4         7         9         3         8         6\n","479515         4         7         9         3         8         7\n","479516         4         7         9         3         8         8\n","479517         4         7         9         3         8         9\n","479518         4         7         9         3         9         0\n","\n","[479519 rows x 6 columns]\n","y =  0         10\n","1         10\n","2         10\n","3         10\n","4         10\n","          ..\n","479514     2\n","479515     2\n","479516     2\n","479517     2\n","479518     2\n","Name: category, Length: 479519, dtype: int64\n","x_train =          Domain_0  Domain_1  Domain_2  Domain_3  Domain_4  Domain_5\n","449783         4         4         9         6         6         0\n","316068         3         1         5         9         7         1\n","15804          0         1         5         8         0         3\n","404749         4         0         4         6         3         0\n","416828         4         1         6         7         0         7\n","...          ...       ...       ...       ...       ...       ...\n","259178         2         5         9         1         0         4\n","365838         3         6         5         7         2         8\n","131932         1         3         1         9         0         6\n","146867         1         4         6         8         3         5\n","121958         1         2         1         9         3         8\n","\n","[287711 rows x 6 columns]\n","x_test =          Domain_0  Domain_1  Domain_2  Domain_3  Domain_4  Domain_5\n","247730         2         4         7         6         5         9\n","104270         1         0         4         2         5         2\n","6079           0         0         6         0         8         0\n","337907         3         3         7         8         0         4\n","73030          0         7         3         0         1         8\n","...          ...       ...       ...       ...       ...       ...\n","76941          0         7         6         9         2         9\n","34301          0         3         4         2         9         9\n","102884         1         0         2         8         6         6\n","234276         2         3         4         2         1         0\n","84500          0         8         4         4         8         6\n","\n","[191808 rows x 6 columns]\n","y_train =          Domain_0  Domain_1  Domain_2  Domain_3  Domain_4  Domain_5\n","449783         4         4         9         6         6         0\n","316068         3         1         5         9         7         1\n","15804          0         1         5         8         0         3\n","404749         4         0         4         6         3         0\n","416828         4         1         6         7         0         7\n","...          ...       ...       ...       ...       ...       ...\n","259178         2         5         9         1         0         4\n","365838         3         6         5         7         2         8\n","131932         1         3         1         9         0         6\n","146867         1         4         6         8         3         5\n","121958         1         2         1         9         3         8\n","\n","[287711 rows x 6 columns]\n","y_test =  247730    4\n","104270    5\n","6079      9\n","337907    3\n","73030     5\n","         ..\n","76941     5\n","34301     7\n","102884    5\n","234276    4\n","84500     5\n","Name: category, Length: 191808, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n","  \"X does not have valid feature names, but\"\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","#No. of columns\n","n = encoded_data.shape[1]\n","print(\"total colums are = \", n)\n","\n","print (\"X = \", x) \n","print (\"y = \", y)\n","\n","########################################\n","# Test and Train Split\n","x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.4, random_state=42)\n","\n","print('x_train = ', x_train) \n","print('x_test = ', x_test) \n","print('y_train = ', x_train) \n","print('y_test = ', y_test)\n","\n","########################################\n","\n","#Scaling the data\n","#We usually dont scale the y variable, so need to check this\n","#Separate Target Variable and Predictor Variables\n","\n","\n","#Sandardization of data\n","from sklearn.preprocessing import StandardScaler \n","PredictorScaler=StandardScaler() \n","TargetVarScaler=StandardScaler()\n","\n","#Storing the fit object for later reference\n","PredictorScalerFit=PredictorScaler.fit(x_train) \n","\n","#Generating the standardized values of X and y\n","x_train=PredictorScalerFit.transform(x_train)    \n","x_test=PredictorScalerFit.transform(x_train)   # Should we scale test data according to train set , see \n","\n","\n","###################################\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142981,"status":"ok","timestamp":1655111544764,"user":{"displayName":"Dr MAG","userId":"10163411640105691678"},"user_tz":-60},"id":"WEQVfeABSoC1","outputId":"293420f6-fea0-4094-a948-96999fc48186"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","14386/14386 [==============================] - 20s 1ms/step - loss: 0.5493\n","Epoch 2/5\n","14386/14386 [==============================] - 20s 1ms/step - loss: 0.0751\n","Epoch 3/5\n","14386/14386 [==============================] - 20s 1ms/step - loss: 0.0697\n","Epoch 4/5\n","14386/14386 [==============================] - 20s 1ms/step - loss: 0.0690\n","Epoch 5/5\n","14386/14386 [==============================] - 20s 1ms/step - loss: 0.0688\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6d289a8c90>"]},"metadata":{},"execution_count":25}],"source":["from keras.models import Sequential\n","from keras.layers import Dense\n"," \n","#input_size = 100   # For Hashinh\n","#input_size = 19    # For Binary\n","input_size = 6      # For Base N\n","\n","input_neurons = 5\n","\n","# create ANN model\n","model = Sequential()\n"," \n","# Defining the Input layer and FIRST hidden layer, both are same!\n","model.add(Dense(units=5, input_dim=input_size, kernel_initializer='normal', activation='relu'))  # Find code to find these I/P features automatically \n"," \n","# Defining the Second layer of the model\n","# after the first layer we don't have to specify input_dim as keras configure it automatically\n","model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n"," \n","# The output neuron is a single fully connected node \n","# Since we will be predicting a single number\n","model.add(Dense(1, kernel_initializer='normal'))\n"," \n","# Compiling the model\n","model.compile(loss='mean_squared_error', optimizer='adam')\n"," \n","# Fitting the ANN to the Training set\n","model.fit(x_train, y_train,batch_size = 20, epochs = 5, verbose=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3aWEfhXMTUr","outputId":"8b98d720-9e24-4c9e-f92c-76eeefaadfef"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:133: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.1901\n","Epoch 2/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0262\n","Epoch 3/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0259\n","Epoch 4/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0256\n","Epoch 5/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0260\n","Epoch 6/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0257\n","Epoch 7/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0256\n","Epoch 8/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0256\n","Epoch 9/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0256\n","Epoch 10/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0258\n","###################################################################### Accuracy: 60.25148602080457\n","Epoch 1/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.2681\n","Epoch 2/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0378\n","Epoch 3/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0373\n","Epoch 4/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0369\n","Epoch 5/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0370\n","Epoch 6/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0369\n","Epoch 7/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0371\n","Epoch 8/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0370\n","Epoch 9/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0370\n","Epoch 10/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0367\n","###################################################################### Accuracy: 60.186900622402334\n","Epoch 1/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.2199\n","Epoch 2/10\n","23017/23017 [==============================] - 41s 2ms/step - loss: 3.0328\n","Epoch 3/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0331\n","Epoch 4/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0326\n","Epoch 5/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0327\n","Epoch 6/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0330\n","Epoch 7/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0327\n","Epoch 8/10\n","23017/23017 [==============================] - 38s 2ms/step - loss: 3.0323\n","Epoch 9/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0324\n","Epoch 10/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0323\n","###################################################################### Accuracy: 59.52513533702884\n","Epoch 1/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.2284\n","Epoch 2/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0284\n","Epoch 3/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0276\n","Epoch 4/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0271\n","Epoch 5/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0273\n","Epoch 6/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0270\n","Epoch 7/10\n","23017/23017 [==============================] - 41s 2ms/step - loss: 3.0274\n","Epoch 8/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0273\n","Epoch 9/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0273\n","Epoch 10/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0274\n","###################################################################### Accuracy: 58.94174979092373\n","Epoch 1/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.1939\n","Epoch 2/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0276\n","Epoch 3/10\n","23017/23017 [==============================] - 41s 2ms/step - loss: 3.0277\n","Epoch 4/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0276\n","Epoch 5/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0274\n","Epoch 6/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0273\n","Epoch 7/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0273\n","Epoch 8/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0275\n","Epoch 9/10\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0274\n","Epoch 10/10\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0273\n","###################################################################### Accuracy: 59.540003972548796\n","Epoch 1/20\n","23017/23017 [==============================] - 43s 2ms/step - loss: 3.2293\n","Epoch 2/20\n","23017/23017 [==============================] - 41s 2ms/step - loss: 3.0258\n","Epoch 3/20\n","23017/23017 [==============================] - 41s 2ms/step - loss: 3.0256\n","Epoch 4/20\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0251\n","Epoch 5/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0248\n","Epoch 6/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0250\n","Epoch 7/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0254\n","Epoch 8/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0251\n","Epoch 9/20\n","23017/23017 [==============================] - 42s 2ms/step - loss: 3.0249\n","Epoch 10/20\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0253\n","Epoch 11/20\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0247\n","Epoch 12/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0247\n","Epoch 13/20\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0252\n","Epoch 14/20\n","23017/23017 [==============================] - 41s 2ms/step - loss: 3.0253\n","Epoch 15/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0250\n","Epoch 16/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0251\n","Epoch 17/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0252\n","Epoch 18/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0248\n","Epoch 19/20\n","23017/23017 [==============================] - 39s 2ms/step - loss: 3.0251\n","Epoch 20/20\n","23017/23017 [==============================] - 40s 2ms/step - loss: 3.0251\n","###################################################################### Accuracy: 60.07761899601771\n","Epoch 1/20\n","23017/23017 [==============================] - 41s 2ms/step - loss: 3.2724\n","Epoch 2/20\n"," 4881/23017 [=====>........................] - ETA: 33s - loss: 3.0461"]}],"source":["###############\n","# IMP\n","###############\n","\n","# DOnt run this cell as this will take a lot of time\n","'''\n","\n","# Defining a function to find the best parameters for ANN\n","def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n","    \n","    # Defining the list of hyper parameters to try\n","    batch_size_list=[5, 10, 15, 20]\n","    epoch_list  =   [5, 10, 50, 100]\n","    \n","    import pandas as pd\n","    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n","    \n","    # initializing the trials\n","    TrialNumber=0\n","    for batch_size_trial in batch_size_list:\n","        for epochs_trial in epoch_list:\n","            TrialNumber+=1\n","            # create ANN model\n","            model = Sequential()\n","            # Defining the first layer of the model\n","            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n","\n","            # Defining the Second layer of the model\n","            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n","\n","            # The output neuron is a single fully connected node \n","            # Since we will be predicting a single number\n","            model.add(Dense(1, kernel_initializer='normal'))\n","\n","            # Compiling the model\n","            model.compile(loss='mean_squared_error', optimizer='adam')\n","\n","            # Fitting the ANN to the Training set\n","            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n","\n","            MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n","            \n","            # printing the results of the current iteration\n","            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)\n","            \n","            SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n","                                                                    columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n","    return(SearchResultsData)\n","\n","\n","######################################################\n","# Calling the function\n","ResultsData=FunctionFindBestParams(x_train, y_train, x_test, y_test)\n","\n","# Defining a function to find the best parameters for ANN\n","def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n","    \n","    # Defining the list of hyper parameters to try\n","    batch_size_list=[5, 10, 15, 20]\n","    epoch_list  =   [5, 10, 50, 100]\n","    \n","    import pandas as pd\n","    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n","    \n","    # initializing the trials\n","    TrialNumber=0\n","    for batch_size_trial in batch_size_list:\n","        for epochs_trial in epoch_list:\n","            TrialNumber+=1\n","            # create ANN model\n","            model = Sequential()\n","            # Defining the first layer of the model\n","            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n"," \n","            # Defining the Second layer of the model\n","            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n"," \n","            # The output neuron is a single fully connected node \n","            # Since we will be predicting a single number\n","            model.add(Dense(1, kernel_initializer='normal'))\n"," \n","            # Compiling the model\n","            model.compile(loss='mean_squared_error', optimizer='adam')\n"," \n","            # Fitting the ANN to the Training set\n","            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n"," \n","            MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n","            \n","            # printing the results of the current iteration\n","            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)\n","            \n","            SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n","                                                                    columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n","    return(SearchResultsData)\n"," \n"," \n","######################################################\n","# Calling the function\n","ResultsData=FunctionFindBestParams(x_train, y_train, x_test, y_test)\n","'''\n","\n","###########################################\n","# Grid Search to find parameters\n","# Be careful, as it can take too long,\n","##########################################\n","\n","input_size  = 100\n","\n","# Function to generate Deep ANN model \n","def make_regression_ann(Optimizer_trial):\n","    from keras.models import Sequential\n","    from keras.layers import Dense\n","    \n","    model = Sequential()\n","    model.add(Dense(units=5, input_dim=input_size, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(1, kernel_initializer='normal'))\n","    model.compile(loss='mean_squared_error', optimizer=Optimizer_trial)\n","    return model\n","\n","###########################################\n","from sklearn.model_selection import GridSearchCV\n","from keras.wrappers.scikit_learn import KerasRegressor\n","\n","# Listing all the parameters to try\n","Parameter_Trials={'batch_size':[10,20,30],\n","                      'epochs':[10,20],\n","                    'Optimizer_trial':['adam', 'rmsprop']\n","                 }\n","\n","# Creating the regression ANN model\n","RegModel=KerasRegressor(make_regression_ann, verbose=0)\n","\n","###########################################\n","from sklearn.metrics import make_scorer\n","\n","# Defining a custom function to calculate accuracy\n","def Accuracy_Score(orig,pred):\n","    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n","    print('#'*70,'Accuracy:', 100-MAPE)\n","    return(100-MAPE)\n","\n","custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n","\n","#########################################\n","# Creating the Grid search space\n","# See different scoring methods by using sklearn.metrics.SCORERS.keys()\n","grid_search=GridSearchCV(estimator=RegModel, \n","                         param_grid=Parameter_Trials, \n","                         scoring=custom_Scoring, \n","                         cv=5)\n","\n","#########################################\n","# Measuring how much time it took to find the best params\n","import time\n","StartTime=time.time()\n","\n","# Running Grid Search for different paramenters\n","grid_search.fit(x_train,y_train, verbose=1)\n","\n","EndTime=time.time()\n","print(\"########## Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes')\n","\n","print('### Printing Best parameters ###')\n","grid_search.best_params_\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"executionInfo":{"elapsed":260,"status":"error","timestamp":1655044571630,"user":{"displayName":"Dr MAG","userId":"10163411640105691678"},"user_tz":-60},"id":"o0RO2XhzNDVP","outputId":"bdde5e5b-ef42-492a-ef6a-28c32c134883"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_535/2402311432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mResultsData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Parameters'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'line'\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#batch size, epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ResultsData' is not defined"]}],"source":["\n","%matplotlib inline\n","#ResultsData.plot(x='Parameters', y='Accuracy', figsize=(15,4), kind='line')   #batch size, epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7P-SBqANI_x","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1655111666235,"user_tz":-60,"elapsed":116902,"user":{"displayName":"Dr MAG","userId":"10163411640105691678"}},"outputId":"1be9c8e4-f715-4bf8-8258-732c88b95729"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Domain_0  Domain_1  Domain_2  Domain_3  Domain_4  Domain_5  Price  \\\n","0 -0.290533 -1.582462 -1.020690 -1.381716 -1.382244 -2.111497   10.0   \n","1 -0.815573 -1.962669 -1.506019 -1.018273 -1.261115 -1.990596    NaN   \n","2 -2.390694 -1.962669 -1.506019 -1.139420 -2.109020 -1.748795   10.0   \n","3 -0.290533 -2.089405 -1.627351 -1.381716 -1.745632 -2.111497    NaN   \n","4 -0.290533 -1.962669 -1.384687 -1.260568 -2.109020 -1.265193    NaN   \n","\n","   PredictedPrice  \n","0        4.672931  \n","1        6.907020  \n","2       13.075829  \n","3        4.998135  \n","4        4.916807  "],"text/html":["\n","  <div id=\"df-f00a6843-560b-4806-a9b8-628f6d2807df\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Domain_0</th>\n","      <th>Domain_1</th>\n","      <th>Domain_2</th>\n","      <th>Domain_3</th>\n","      <th>Domain_4</th>\n","      <th>Domain_5</th>\n","      <th>Price</th>\n","      <th>PredictedPrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.290533</td>\n","      <td>-1.582462</td>\n","      <td>-1.020690</td>\n","      <td>-1.381716</td>\n","      <td>-1.382244</td>\n","      <td>-2.111497</td>\n","      <td>10.0</td>\n","      <td>4.672931</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.815573</td>\n","      <td>-1.962669</td>\n","      <td>-1.506019</td>\n","      <td>-1.018273</td>\n","      <td>-1.261115</td>\n","      <td>-1.990596</td>\n","      <td>NaN</td>\n","      <td>6.907020</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.390694</td>\n","      <td>-1.962669</td>\n","      <td>-1.506019</td>\n","      <td>-1.139420</td>\n","      <td>-2.109020</td>\n","      <td>-1.748795</td>\n","      <td>10.0</td>\n","      <td>13.075829</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.290533</td>\n","      <td>-2.089405</td>\n","      <td>-1.627351</td>\n","      <td>-1.381716</td>\n","      <td>-1.745632</td>\n","      <td>-2.111497</td>\n","      <td>NaN</td>\n","      <td>4.998135</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.290533</td>\n","      <td>-1.962669</td>\n","      <td>-1.384687</td>\n","      <td>-1.260568</td>\n","      <td>-2.109020</td>\n","      <td>-1.265193</td>\n","      <td>NaN</td>\n","      <td>4.916807</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f00a6843-560b-4806-a9b8-628f6d2807df')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f00a6843-560b-4806-a9b8-628f6d2807df button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f00a6843-560b-4806-a9b8-628f6d2807df');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}],"source":["##########################\n","# Error with best Best Parameters\n","##########################\n","\n","\n","# Fitting the ANN to the Training set\n","model.fit(x_train, y_train ,batch_size = 15, epochs = 5, verbose=0)\n","\n","# Generating Predictions on testing data\n","Predictions=model.predict(x_test)\n","\n","# Scaling the predicted Price data back to original price scale\n","#Predictions=TargetVarScalerFit.inverse_transform(Predictions)\n","\n","# Scaling the y_test Price data back to original price scale\n","#y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n","y_test_orig = y_test\n","\n","# Scaling the test data back to original scale\n","#Test_Data=PredictorScalerFit.inverse_transform(x_train)\n","Test_Data = x_test\n","\n","TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n","TestingData['Price']=y_test_orig\n","TestingData['PredictedPrice']=Predictions\n","TestingData.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1655112317680,"user":{"displayName":"Dr MAG","userId":"10163411640105691678"},"user_tz":-60},"id":"BWltTXaCfj3a","outputId":"4841628a-600e-4509-d51f-84e1559ac63f"},"outputs":[{"output_type":"stream","name":"stdout","text":["The Accuracy of ANN model is: 4.9869672841405475\n"]},{"output_type":"execute_result","data":{"text/plain":["   Domain_0  Domain_1  Domain_2  Domain_3  Domain_4  Domain_5  Price  \\\n","0 -0.290533 -1.582462 -1.020690 -1.381716 -1.382244 -2.111497   10.0   \n","1 -0.815573 -1.962669 -1.506019 -1.018273 -1.261115 -1.990596    NaN   \n","2 -2.390694 -1.962669 -1.506019 -1.139420 -2.109020 -1.748795   10.0   \n","3 -0.290533 -2.089405 -1.627351 -1.381716 -1.745632 -2.111497    NaN   \n","4 -0.290533 -1.962669 -1.384687 -1.260568 -2.109020 -1.265193    NaN   \n","\n","   PredictedPrice        APE  \n","0        4.672931  53.270693  \n","1        6.907020        NaN  \n","2       13.075829  30.758286  \n","3        4.998135        NaN  \n","4        4.916807        NaN  "],"text/html":["\n","  <div id=\"df-4bd9872b-0410-44e8-9faa-c0d759039a2e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Domain_0</th>\n","      <th>Domain_1</th>\n","      <th>Domain_2</th>\n","      <th>Domain_3</th>\n","      <th>Domain_4</th>\n","      <th>Domain_5</th>\n","      <th>Price</th>\n","      <th>PredictedPrice</th>\n","      <th>APE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.290533</td>\n","      <td>-1.582462</td>\n","      <td>-1.020690</td>\n","      <td>-1.381716</td>\n","      <td>-1.382244</td>\n","      <td>-2.111497</td>\n","      <td>10.0</td>\n","      <td>4.672931</td>\n","      <td>53.270693</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.815573</td>\n","      <td>-1.962669</td>\n","      <td>-1.506019</td>\n","      <td>-1.018273</td>\n","      <td>-1.261115</td>\n","      <td>-1.990596</td>\n","      <td>NaN</td>\n","      <td>6.907020</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.390694</td>\n","      <td>-1.962669</td>\n","      <td>-1.506019</td>\n","      <td>-1.139420</td>\n","      <td>-2.109020</td>\n","      <td>-1.748795</td>\n","      <td>10.0</td>\n","      <td>13.075829</td>\n","      <td>30.758286</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.290533</td>\n","      <td>-2.089405</td>\n","      <td>-1.627351</td>\n","      <td>-1.381716</td>\n","      <td>-1.745632</td>\n","      <td>-2.111497</td>\n","      <td>NaN</td>\n","      <td>4.998135</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.290533</td>\n","      <td>-1.962669</td>\n","      <td>-1.384687</td>\n","      <td>-1.260568</td>\n","      <td>-2.109020</td>\n","      <td>-1.265193</td>\n","      <td>NaN</td>\n","      <td>4.916807</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bd9872b-0410-44e8-9faa-c0d759039a2e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4bd9872b-0410-44e8-9faa-c0d759039a2e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4bd9872b-0410-44e8-9faa-c0d759039a2e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":27}],"source":["\n","# Computing the absolute percent error\n","APE=100*(abs(TestingData['Price']-TestingData['PredictedPrice'])/TestingData['Price'])\n","TestingData['APE']=APE\n","\n","print('The Accuracy of ANN model is:', np.abs(100-np.mean(APE)))\n","TestingData.head()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1655031334141,"user":{"displayName":"Dr MAG","userId":"10163411640105691678"},"user_tz":-60},"id":"PMAE_sBcYqlS","outputId":"1b29a028-48fc-474d-85dd-ff1a24d1ea5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n","Not connected to a GPU\n"]}],"source":["# Seeing stats of Google pro\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DomainPricePrediction_Regression_NN","provenance":[{"file_id":"1mtFelBaqVO3eNfMqj9_ydS2fV2hTaBjM","timestamp":1655024687294}],"mount_file_id":"18DgE72BMSvZnivFpW9OmsLzPrWMdplmD","authorship_tag":"ABX9TyM2FuTSkEoIqZSdMsVheqEZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}